---
title: "mlproject"
author: "Shu_Pang_Rebecca"
date: '2024-04-24'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(r02pro)     #INSTALL IF NECESSARY
library(tidyverse)  #INSTALL IF NECESSARY
library(MASS)
library(tree)
library(randomForest)
library(nnet)
library(caret)
library(pROC)
```

#read data
```{r}
df=read.csv("cancer patient data sets.csv")

#change character into numerical
levels <- c("Low","Medium" ,"High")
codes <- c(0, 1, 1)
df$Level <- codes[match(df$Level, levels)]
df$Level <- as.factor(df$Level)  # factor
df=na.omit(df)
library(dplyr)
df <- df %>% dplyr::select(Level, Age, Gender, Air.Pollution, Genetic.Risk, OccuPational.Hazards, Smoking) %>%
  na.omit()
df

set.seed(123)
random_ind <- sample(nrow(df), size=nrow(df),replace=F)
num <- 1:(nrow(df)/5)


traindf <- df[-num, ]
testdf <- df[num, ]
head(traindf)
head(testdf)
nrow(df)
nrow(traindf)
nrow(testdf)

#df
#model <- glm(Level ~ ., data=df, family = "binomial")
#summary(model)
```

#1. logistic regression
```{r}
#training
model_lm <- glm(as.factor(Level) ~ Age + Gender + Air.Pollution + Genetic.Risk + OccuPational.Hazards + Smoking, data = traindf,family = "binomial")

predicted <- predict(model_lm, traindf,type = "response")
predicted_classes <- ifelse(predicted > 0.5, 1, 0)
#prediction of train data in logistics
confusionMatrix(factor(predicted_classes), factor(traindf$Level))
mean(predicted_classes != traindf$Level)

#testing
predicted.te <- predict(model_lm, newdata=testdf,type = "response")
predicted_te.classes <- ifelse(predicted.te > 0.5, 1, 0)
#prediction of test data in logistics
confusionMatrix(factor(predicted_te.classes), factor(testdf$Level))
mean(predicted_te.classes != testdf$Level)

# ROC  AUC
roc_obj <- roc(traindf$Level, predicted)
print(auc(roc_obj))
plot(roc_obj, main = "ROC Curve", col = "#1c61b6", lwd = 2)
abline(a = 0, b = 1, lty = 2, col = "gray")

```

#1.1 k-fold only for logistics regression
```{r}
set.seed(123)
df <- df[sample(nrow(df)), ] # random order of data

# calculate the size of train and test
fold_size <- ceiling(nrow(df) / 10)
folds <- cut(seq(1, nrow(df)), breaks = 10, labels = FALSE)

# vector
training_errors <- numeric(10)
test_errors <- numeric(10)

# 10-fold
for (i in 1:10) {
  # split data
  test_indices <- which(folds == i)
  test_data <- df[test_indices, ]
  train_data <- df[-test_indices, ]
  
  # fit
  model <- glm(as.factor(Level) ~ ., family = "binomial", data = train_data)
  
  # test error
  test_predictions <- predict(model, newdata=test_data, type = "response")
  test_predicted_classes <- ifelse(test_predictions > 0.5, 1, 0)
  test_errors[i] <- mean(test_predicted_classes != test_data$Level)
  
  # train error
  train_predictions <- predict(model, train_data, type = "response")
  train_predicted_classes <- ifelse(train_predictions > 0.5, 1, 0)
  training_errors[i] <- mean(train_predicted_classes != train_data$Leve)
}

# mean train/test error
average_training_error <- mean(training_errors)
average_test_error <- mean(test_errors)

# print
cat("Average Training Error:", average_training_error, "\n")
cat("Average Test Error:", average_test_error, "\n")
```




#2. Random forest--> Have to do training/testing erros
```{r}
set.seed(1)
#training
mod_rf <- randomForest(Level ~  Age + Gender + Air.Pollution + Genetic.Risk + OccuPational.Hazards + Smoking, data = traindf, importance=TRUE)
predictions_rf <- predict(mod_rf, newdata = traindf)
confusionMatrix(predictions_rf, traindf$Level)

importance(mod_rf)
varImpPlot(mod_rf)

#mean(predictions_rf != df$Level[-traindf,])

#testing
predictions_rf_te <- predict(mod_rf, newdata = testdf)
confusionMatrix(predictions_rf_te, testdf$Level)

```
#2.2 bagging need or not
```{r}

#training
p <- ncol(df)-1
bag.tr <- randomForest(as.factor(Level) ~ Age + Gender + Air.Pollution + Genetic.Risk + OccuPational.Hazards + Smoking, data = traindf,  mtry = p, importance=TRUE)
bag.tr

predictions <- predict(bag.tr, traindf)
accuracy <- sum(predictions == traindf$Level) / nrow(traindf)
print(paste("Accuracy:", accuracy))
confusionMatrix <- table(Predicted = predictions, Actual = traindf$Level)
print(confusionMatrix)


importance(bag.tr)
varImpPlot(bag.tr)

#testing

predictions <- predict(bag.tr, testdf)
accuracy <- sum(predictions == testdf$Level) / nrow(testdf)
print(paste("Accuracy:", accuracy))
confusionMatrix <- table(Predicted = predictions, Actual = testdf$Level)
print(confusionMatrix)

```


#3. k means
```{r}
df1=df[,-1]
numeric_df <- df1[, sapply(df1, is.numeric)]
km_result <- kmeans(numeric_df, centers = 2, nstart = 5)
km_result$size
km_result$centers
```